input {
  jdbc {
# 	https://dlm.mariadb.com/3852266/Connectors/java/connector-java-3.4.1/mariadb-java-client-3.4.1.jar
    jdbc_driver_library => "/lib/jars/mariadb-java-client-3.4.1.jar"
    jdbc_driver_class => "org.mariadb.jdbc.Driver"
    jdbc_connection_string => "jdbc:mariadb://15.165.236.50:3306/S11P21D108"
    jdbc_user => "root"
    jdbc_password => "enqnrhkwk108"
    schedule => "*/10 * * * *"  # 5분에 한번씩 실행
    statement => "
      SELECT id, area_name, COALESCE(view, 0) AS view
      FROM area
    "
    use_column_value => true
#     시간 기반의 추적이 필요하다면 updated_at이나 created_at 같은 시간 필드를 사용하는 것이 더 일반적입니다.
# Elasticsearch는 document_id가 동일한 경우 새 데이터를 기존 문서에 업데이트합니다.
    tracking_column => "view" # view를 사용하는건 적합하지 않지만, 여기서는 그냥 사용
    last_run_metadata_path => "/var/lib/logstash/metadata/last_run_metadata_area.yml"  # Logstash 서버 내부의 폴더
  }
  jdbc {
      jdbc_driver_library => "/lib/jars/mariadb-java-client-3.4.1.jar"
      jdbc_driver_class => "org.mariadb.jdbc.Driver"
      jdbc_connection_string => "jdbc:mariadb://15.165.236.50:3306/S11P21D108"
      jdbc_user => "root"
      jdbc_password => "enqnrhkwk108"
        schedule => "3-59/10 * * * *"  # 세 번째 쿼리는 매 5분 마다 2분씩 지연
      statement => "
        SELECT
            area.id AS area_id,
            area.area_name AS area_name,
            COUNT(posts.id) AS post_count,
            MAX(posts.updated_at) AS max_updated_at
        FROM
            area
                LEFT JOIN
            boards ON boards.area_id = area.id
                LEFT JOIN
            posts ON posts.board_id = boards.id AND posts.created_at > DATE_SUB(NOW(), INTERVAL 7 DAY)
        GROUP BY
            area.id;
      "
      use_column_value => true
      tracking_column => "max_updated_at"
      last_run_metadata_path => "/var/lib/logstash/metadata/last_run_metadata_area_posts.yml"  # 다른 경로로 설정
    }

    jdbc {
      jdbc_driver_library => "/lib/jars/mariadb-java-client-3.4.1.jar"
      jdbc_driver_class => "org.mariadb.jdbc.Driver"
      jdbc_connection_string => "jdbc:mariadb://15.165.236.50:3306/S11P21D108"
      jdbc_user => "root"
      jdbc_password => "enqnrhkwk108"
        schedule => "7-59/10 * * * *"  # 세 번째 쿼리는 매 5분 마다 2분씩 지연
      statement => "
        SELECT
            franchises.id AS franchise_id,
            franchises.name AS franchise_name,
            COUNT(posts.id) AS post_count,
            MAX(posts.updated_at) AS max_updated_at
        FROM
            franchises
                LEFT JOIN
            boards ON boards.franchise_id = franchises.id
                LEFT JOIN
            posts ON posts.board_id = boards.id AND posts.created_at > DATE_SUB(NOW(), INTERVAL 7 DAY)
        GROUP BY
            franchises.id;
      "
      use_column_value => true
      tracking_column => "max_updated_at"
      last_run_metadata_path => "/var/lib/logstash/metadata/last_run_metadata_franchises_posts.yml" # 마지막으로 실행된 쿼리의 상태(시점)를 저장하는 파일의 경로를 지정해주는 설정입니다.
    }
}

# # 처음 실행 시 180초(3분) 지연
# # 이후에는 지연을 하지 않도록 설정
# filter {
#   ruby {
#     init => "@sleep_done = false"  # 필터가 처음 초기화될 때 변수를 false로 설정
#     code => "
#       if !@sleep_done
#         sleep(180)  # 처음 실행 시 180초 지연
#         @sleep_done = true  # 이후에는 지연을 하지 않도록 설정
#       end
#     "
#   }
# }



# @version과 @timestamp 필드를 제거
# 데이터 정제: 불필요한 메타데이터가 포함된 데이터를 정리하여 저장 공간을 절약하거나, 불필요한 정보를 줄일 수 있습니다.

filter {
  mutate {
    remove_field => ["@version", "@timestamp"]
  }
}

output {
  if [area_name] and [area_id] {
    elasticsearch {
      index => "area_board_search_term"
      hosts => "${ELASTIC_HOSTS}"
      user => "${ELASTIC_USER}"
      password => "${ELASTIC_PASSWORD}"
#       cacert => "certs/ca/ca.crt"
      ssl => true
      ssl_certificate_authorities => "certs/ca/ca.crt"
      document_id => "%{area_id}-%{area_name}"
    }
  }
  else if [franchise_name] and [franchise_id] {
    elasticsearch {
      index => "franchise_board_search_term"
      hosts => "${ELASTIC_HOSTS}"
      user => "${ELASTIC_USER}"
      password => "${ELASTIC_PASSWORD}"
#       cacert => "certs/ca/ca.crt"
      document_id => "%{franchise_id}-%{franchise_name}"
      ssl => true
      ssl_certificate_authorities => "certs/ca/ca.crt"
    }
  }
  # id와 area_name이 있지만 area_id가 없는 경우 area_search_term 인덱스에 저장됩니다.
  else if [id] and [area_name] and ![area_id] {
    elasticsearch {
      index => "area_search_term"
      hosts=> "${ELASTIC_HOSTS}"
      user=> "${ELASTIC_USER}"
      password=> "${ELASTIC_PASSWORD}"
#       cacert=> "certs/ca/ca.crt"
      ssl => true
      ssl_certificate_authorities => "certs/ca/ca.crt"
      document_id => "%{id}-%{area_name}"
    }
    stdout { codec => rubydebug }
  }
  else {
    # 예상치 못한 데이터 형식에 대한 처리
    stdout { codec => rubydebug }
    file {
      path => "/path/to/unexpected_data.log"
      codec => rubydebug
    }
  }
}

# **DATE_SUB(NOW(), INTERVAL 7 DAY)**와 같은 동적 시간 필드가 사용되면, 매번 쿼리 실행 시 실시간으로 7일 전의 데이터를 동적으로 계산하게 됩니다.
# 데이터가 많을 경우 이 계산이 성능 저하를 유발할 수 있습니다.
# 이를 최적화하는 방법을 살펴보면, 다음과 같은 전략들을 적용할 수 있습니다.
# 1. 시간 필드 인덱싱
# CREATE INDEX idx_posts_created_at ON posts(created_at);

# 3. 쿼리 캐싱
# 목적: 자주 사용되는 쿼리 결과를 캐싱하여, 쿼리가 다시 실행될 때 캐시된 결과를 사용하도록 합니다.
# SET GLOBAL query_cache_size = 1000000;  # 1MB 캐시 설정
# SET GLOBAL query_cache_type = 1;  # Query Cache 활성화

# 4. 실시간 동적 쿼리 대신 스케줄링
  # 목적: 실시간으로 계산하기보다는, 일정 시간에 한 번씩 미리 데이터를 계산하고 저장해 두는 방식입니다.
  # 방법:
  # 데이터를 실시간으로 쿼리하는 대신, 매일 자정이나 일정 시간에 한 번씩 데이터를 미리 계산하고, 그 결과를 임시 테이블이나 캐시된 테이블에 저장해 둡니다.
  # 이후 쿼리에서는 이 미리 계산된 테이블을 사용하여 성능을 최적화할 수 있습니다.
  # 예를 들어,

 # INSERT INTO summary_posts (franchise_id, franchise_name, post_count, max_updated_at)


# .env 파일로 ${} 구문을 사용하여 환경 변수를 불러와 사용 적용하기
# Elasticsearch는 document_id가 동일한 경우 새 데이터를 기존 문서에 업데이트합니다.
# jdbc jar 파일 다운로드 후 권한 664로 변경후 볼륨 설정 해서 서버 안에 넣기



#  elasticsearch {
#    index => "area_search_term"
#    hosts=> "${ELASTIC_HOSTS}"
#    user=> "${ELASTIC_USER}"
#    password=> "${ELASTIC_PASSWORD}"
#    cacert=> "certs/ca/ca.crt"
#    document_id => "%{id}-%{area_name}"
#  }
#  stdout { codec => rubydebug } # 테스트나 디버깅을 끝낸 후에는 이 부분을 비활성화하거나 줄이는 것이 좋습니다.


# output {
#   elasticsearch {
#     index => "area_search_term"
#     hosts=> "${ELASTIC_HOSTS}"
#     user=> "${ELASTIC_USER}"
#     password=> "${ELASTIC_PASSWORD}"
#     cacert=> "certs/ca/ca.crt"
#     document_id => "%{id}-%{area_name}"
#   }
#   stdout { codec => rubydebug } # 테스트나 디버깅을 끝낸 후에는 이 부분을 비활성화하거나 줄이는 것이 좋습니다.
# }