# 자동완성 방법
- 상권 검색어 추천 인덱스 
  - 색인시: 표준 토크나이저, nori 분석기, edge ngram(1~4) 사용 (접두사 부터 접근하는 방식과 형태소로 접근하는 방식에 둘다 대응하기 위해서)
  - 검색시: edge n-gram(1~6) 분석기 사용 (상권의 경우 어느 정도 정보를 알고 단어의 앞부터 완벽한 단어로 검색할 것으로 예상)
    - Dis Max 쿼리 : 필드 간 점수 차이가 클 때, 가장 관련성 높은 결과를 우선순위로 두고 싶을 때

- 게시판 검색어 추천 인덱스
  - 프랜차이즈의 이름을 통해 검색하는 경우:
    - 색인시: 표준 토크나이저, n-gram(1~2), edge ngram(3~4), nori 사용 (n-gram 을 통해 어느 부분이든 2글자 일치 하면 검색 결과에 반영되게 설정)
      - nori 분석기를 사용하여 호식이 두마리치킨 과 같은 것에서 치킨도 색인을 해둬야함.
    - 검색시: n-gram 분석기(1~3) , edge ngram(3~6) 사용 (프랜차이즈 이름은 사전 정보의 한계 때문에 형태소 기반 분석이 어려움. 이름 기억이 잘 안날 수 있으니 접두사 기반 x)
      - Dis Max 쿼리 : 필드 간 점수 차이가 클 때, 가장 관련성 높은 결과를 우선순위로 두고 싶을 때
      - n-gram 으로 부족할 전체 검색에 대해서 edge ngram 으로 커버
  - 상권의 이름을 통해 검색하는 경우:
    - 색인시: 표준 토크나이저, nori 분석기와 edge ngram(1~4) 사용 (접두사 부터 접근하는 방식과 형태소로 접근하는 방식에 둘다 대응하기 위해서)
    - 검색시: edge n-gram(1~6) 분석기 사용 (상권의 경우 어느 정도 정보를 알고 단어의 앞부터 접근할 것으로 예상)
      - Dis Max 쿼리 : 필드 간 점수 차이가 클 때, 가장 관련성 높은 결과를 우선순위로 두고 싶을 때

  - 각 인덱스의 점수 산정이 맞지 않는 것을 해결하기 위해서 boost로 가중치를 각각 검색 분석기 마다 추가
    - 3글자 기준 전체가 같을때의 값이 같도록 
    - 두 인덱스 결과를 최소 20퍼센트를 보장.
    - 남은 결과를 점수 순서대로 병합하여 추가.
색인 시 여러 분석기를 사용하면 각각의 분석 결과가 다른 필드에 저장됩니다.  

추후 한글 jaso-분석기로 변경  

### 여러 분석기를 활용한 검색 예시
- 색인 시 nori_analyzer를 사용하여 텍스트를 의미 단위로 나누어 저장하고, 검색 시 ngram_analyzer를 사용하면 부분 검색과 의미 단위 검색을 혼합할 수 있습니다.
  - 예: "서울에 갔다"라는 문장을 색인할 때 Nori 분석기로 나누면 "서울", "가다"로 나누어 저장되고, 검색할 때 n-gram 분석기를 사용하면 "서" 또는 "서울"만 입력해도 해당 문서를 검색할 수 있습니다.
  - 반대 예:  예를 들어, "서울에 갔다"라는 문장을 nori_analyzer로 색인하면 "서울", "가다"와 같은 단위로 분리되겠죠. 이 경우 검색에서 "서울"을 입력하면 해당 문서를 찾을 수 있지만, "서"처럼 단어의 일부분만 입력했을 때는 검색 결과가 나오지 않습니다.


- 복합어가 많이 등장하지 않고 짧은 상권명이나 프랜차이즈명을 처리한다면 N-gram 분석기가 더 빠르고 효율적일 수 있지만, 
복합어가 많거나 고유 명사 처리가 중요한 경우는 Nori 분석기가 더 나은 선택일 수 있습니다.
  - 고유 명사는 인식을 못할 확률이 높다. -> 표준 토크나이저
  
## nori를 이용한 자동완성
- 의미 단위로 검색
- 단어 간의 관계 파악
- 복합어 처리
즉, 단어 2개 이상에서 장점 발휘

## N-gram 을 이용한 자동완성
상권이나 프랜차이즈명과 같은 경우는 중간 단어만 기억나거나 중간 단어가 핵심인 경우가 상당수 있으므로   
접두사 기반 Edge N-gram보다 N-gram이 적합하다고 판단.

# 개념
## 색인(Indexing)이란?
색인 과정은 데이터를 Elasticsearch에 저장하는 과정입니다. 이때 **색인 분석기(analyzer)**는 데이터를 어떻게 저장할지를 결정합니다.  
색인 시: 문서를 Elasticsearch에 넣을 때, 분석기가 데이터를 처리하여 토큰(단어 단위)으로 나누고, 이 토큰들이 인덱스에 저장됩니다.  
예를 들어, 서울이라는 단어를 n-gram 분석기로 색인하면 서, 서울, 울과 같은 토큰들이 저장됩니다.

## 검색(Search)이란?
검색 과정은 사용자가 Elasticsearch에 쿼리를 보낼 때, 해당 쿼리를 분석하고 결과를 반환하는 과정입니다. **검색 분석기(search_analyzer)**는 쿼리(검색어)를 어떻게 처리할지를 결정합니다.  
검색 시: 사용자가 검색어를 입력하면, 이 검색어는 검색 분석기에 의해 처리됩니다. 분석된 검색어는 색인된 토큰들과 비교되어 검색 결과가 반환됩니다.  
예를 들어, 서울을 검색하면 검색어도 동일한 방식으로 나누어져 저장된 토큰과 매칭됩니다.

## 분석기

### 간단 비교
| **분석기**         | **색인 시 특징**                                        | **검색 시 특징**                                         | **사용 사례**                            |
|--------------------|--------------------------------------------------------|----------------------------------------------------------|------------------------------------------|
| **Edge N-gram**     | 단어의 앞부분에서만 n-gram 생성                        | 검색어의 앞부분만 매칭 가능                              | 자동완성, 빠른 앞부분 매칭               |
| **N-gram**          | 단어의 모든 부분에서 n-gram 생성                       | 검색어의 앞, 중간, 뒷부분 어디서든 매칭 가능             | 오타 보정, 부분 매칭 검색                |
| **노리(Nori)**      | 한국어 형태소 분석을 통해 어근 및 단어의 형태를 분석    | 형태소 기반으로 정확한 단어 매칭 및 어근 기반 검색       | 한국어 문법, 형태소 검색                 |
| **표준 토크나이저** | 공백 및 구두점을 기준으로 단어 단위로 텍스트를 분리    | 단어 단위로 매칭하며, 띄어쓰기가 있는 언어에서 효율적    | 영어 및 띄어쓰기가 있는 언어 텍스트 분석 |

### nori vs n-gram
| **특징**              | **nori 분석기**                                                                                       | **n-gram 분석기**                                                                                 |
|-----------------------|-------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| **주요 목적**          | 한국어와 같은 형태소 기반 언어를 위한 의미 단위 분석                                                   | 텍스트를 문자 단위로 잘라서 부분 검색 가능                                                       |
| **색인 시 역할**       | 텍스트를 **형태소(의미 단위)**로 나누어 저장 (예: "서울에 갔다" -> "서울", "가다")                     | 텍스트를 n개의 문자로 잘라서 저장 (예: "서울" -> "서", "서울", "울")                              |
| **검색 시 역할**       | 사용자의 검색어를 형태소 단위로 분리하여 검색 (예: "갔다" 검색 -> "가다" 포함 문서 검색 가능)            | 사용자가 입력한 검색어의 일부만으로도 검색 가능 (예: "서" 검색 -> "서울" 문서 검색 가능)           |
| **주 사용 예**         | 의미 단위로 검색이 필요한 경우 (예: 뉴스 기사 검색, 긴 텍스트 분석)                                    | 자동 완성, 부분 검색, 연관 검색이 필요한 경우 (예: 검색어 자동완성, 검색어 일부 입력)              |
| **단점**               | 형태소 분석이기 때문에 짧은 자음/모음 검색에는 적합하지 않음                                           | 문자의 순서를 단순히 자르기 때문에 의미 단위로는 분석하지 않음                                  |
| **장점**               | 한국어와 같이 어미가 변하는 언어에서 의미 있는 검색이 가능                                              | 자음/모음 단위로 검색이 가능해 사용자가 불완전한 검색어를 입력해도 관련 문서를 검색할 수 있음     |

### 검색시, 여러 분석기 사용 방법
Multi-match 쿼리: 여러 필드의 점수를 합산하거나 병합하여 계산
Dis Max 쿼리: 여러 쿼리 중에서 가장 높은 점수를 가진 결과를 선택

#### 둘 중 어느 것이 자주 쓰이는가?
Multi-match 쿼리는 여러 필드에서 동시에 검색을 할 때 자주 사용되며, 추천 기능에서도 필드별 가중치(Boosting)를 주어 사용자가 입력한 검색어에 대해 다양한 필드에서의 매칭을 확인할 수 있어 범용성이 높습니다.
Dis Max 쿼리는 필드 간 점수 차이가 크고, 가장 관련성 높은 결과를 우선하여 보여줄 때 유용합니다. 검색어 추천보다는 다양한 필드에서 점수를 비교하여 가장 관련성 높은 결과를 도출하는 데 주로 사용됩니다.


## 인덱스 수정 방법
1. 임시 인덱스 생성
2. 현재 인덱스 데이터 임시 인덱스로 이동
3. 현재 인덱스 삭제
4. 새로운 인덱스 생성
5. 임시인덱스 데이터 새로운 인덱스로 이동
6. 임시 인덱스 삭제


### 궁금증

> 검색어가 **"자동차"**일 때, 여러 필드가 각각 다른 색인 방식으로 처리되었을 때의 점수 산정을 예시에서  
Edge N-gram(1~4) 필드와 Standard 토크나이저 필드의 점수는 같을까?

**다르다.**

Standard 토크나이저 필드는 단어 전체가 기준이 되므로 정확한 일치가 매우 중요합니다. 따라서 완전 일치 시에는 가장 높은 점수가 부여됩니다.
Edge N-gram 필드는 앞부분 일치를 기반으로 부분 매칭도 가능하게 설계되었기 때문에, 완전 일치 시에도 Standard 필드보다 약간 낮은 점수를 받을 수 있습니다. 
이유는 부분 매칭이 가능한 구조이기 때문에, 완전 매칭에 대한 점수는 완전 매칭에만 집중하는 Standard 필드보다 덜 엄격할 수 있습니다.

> dis_max 쿼리에서 tie_breaker 값의 효과

- tie_breaker가 0일 때:  
  - 각 필드에서의 점수가 아무리 비슷하더라도, 가장 높은 점수를 가진 필드만 최종 점수로 반영됩니다.  
  다른 필드에서의 관련성은 전혀 반영되지 않습니다.


- tie_breaker가 1에 가까울 때:
  - 모든 필드에서 점수가 비슷하다면, 각 필드의 점수를 최대한 반영하여 더 정밀한 최종 점수를 계산할 수 있습니다.  
  이는 여러 필드에서 검색어가 매칭되었을 때, 그 필드들이 모두 중요한 경우에 사용할 수 있습니다.  


- 실제 사용 시의 장점  
  - 다중 필드 검색에서 점수의 균형을 맞추고 싶을 때 유용합니다.  
  예를 들어, 검색 결과가 여러 필드에서 거의 비슷한 관련성을 보이는 경우, 특정 필드 하나에만 의존하지 않고 다른 필드의 유사성도 함께 반영할 수 있습니다.      
  특정 필드의 중요도를 더 강조하면서도, 관련성이 떨어지지 않는 필드들의 점수도 약간 반영함으로써 검색 결과의 품질을 높일 수 있습니다.  

- 추천 시 적합한 tie_breaker 설정
  - **추천 정확도를 우선시하고 싶다면 (선택)**, **낮은 값 (0.3 이하)**을 설정해, 가장 관련성 높은 필드의 결과를 우선으로 추천할 수 있습니다.  
  - 추천의 다양성과 유연성을 높이고 싶다면, **중간 값 (0.5 정도)**을 설정하여 여러 필드에서 유사한 결과가 반영되도록 할 수 있습니다.  
  - 다양한 추천어를 제공하고 싶다면, **높은 값 (0.7 이상)**을 설정해 여러 필드의 유사성을 최대한 반영하도록 할 수 있습니다.  
